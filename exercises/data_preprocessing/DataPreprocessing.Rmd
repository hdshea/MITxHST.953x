---
title: "Data Preprocessing"
author: "H. David Shea"
date: "`r format(Sys.time(), '%d %b %Y')`"
output:
  pdf_document:
    toc: yes
  html_document:
    fig.align: center
    fig_caption: yes
    fig_height: 5
    fig_width: 9
    highlight: tango
    theme: united
    #toc: yes
---

(Note:  Updated and modified from the hst953-edx github version.)

```{r setup, include=FALSE}
library(DBI)
library(RSQLite)
library(tidyverse)
library(splitstackshape)

knitr::opts_chunk$set(
    connection = "mimic3", # automatically uses this connection in sql chunks 
    comment = "#>", 
    collapse = TRUE, 
    message = FALSE,
    fig.width = 8,
    fig.asp = ((1 + sqrt(5)) / 2) - 1, # the golden ratio - technically, the b proportion of a+b when a is 1
    out.width = "70%",
    fig.align = "center"
)
```

# Source MIMIC-III demo version data

In the original version (on the hst953-edx github site), they used the MIMIC-III demo version directly loaded.  Now, I have in *project_base_dir*/database/mimic3.db the SQLite version of the full MIMIC-III v1.4 database loaded.  I'll use that in the processing below - with some pre-coded inclusion criteria to extract just the demo data.  The following code chunk attaches the database and loads auxiliary functions for extracting database data (`db_functions.R`) and for doing some MIMIC data interpretation and pre-processing (`mimic3_meta_data.R`) - including the processing to get just the demo data.

```{r source_aux_functions, include=TRUE}
base_dir <- here::here("")
db_dir <- fs::path(base_dir, "database")
db_file <- fs::path(db_dir, "mimic3.db")

if(dbCanConnect(RSQLite::SQLite(), db_file)) {
    mimic3 <- dbConnect(RSQLite::SQLite(), db_file)
}

source(fs::path(base_dir, "db_functions.R"))
source(fs::path(base_dir, "mimic3_meta_data.R"))
```

# Data integration

## Exercise

Aim: This exercise involves combining the separate output datasets exported from separate MIMIC queries into a consistent larger dataset table.

To ensure that the associated observations or rows from the different datasets match up, the right column ID must be used. For example, in MIMIC `SUBJECT_ID` is used to identify each individual patient, so includes their date of birth (DOB), date of death (DOD) and various other clinical detail and laboratory values. Likewise, the hospital admission ID - `HADM_ID` - is used to specifically identify various events and outcomes from an unique hospital admission; and is also in turn associated with the `SUBJECT_ID` of the patient who was involved in that particular hospital admission. Tables pulled from MIMIC can have one or more ID columns. The different tables exported from MIMIC may share some ID columns, which allows us to 'merge' them together, matching up the rows correctly using the unique ID values in their shared ID columns.

To demonstrate this with MIMIC data, some base extraction routines are used to extract some data from the  `ADMISSIONS` and `ICUSTAYS` tables.  We will use these extracted files to show how to merge datasets in R.

1. Base data extractions:

```{r message=FALSE, warning=FALSE}
adm <- db_get_admissions(mimic3, where = demo_subject_ids)

str(adm)

icu <- db_get_icustays(mimic3, where = demo_subject_ids)

str(icu)
```

These base data extraction routines use R's `DBI` package interface to execute SQL statements and pull back data in nicely formatted tibbles.

2. R code: Demonstrating data integration

Merging `ADMISSIONS` and `ICUSTAYS`: to get the rows to match up correctly, we need to merge on both the `SUBJECT_ID` and `HADM_ID`. This is because each subject/patient could have multiple `HADM_ID` from different hospital `ADMISSIONS` during the EHR course of the MIMIC database.

(Note:  in this updated version, I have switched to using the `tidyverse` package relational wrangling techniques instead of the older base `merge` function.)

```{r message=FALSE, warning=FALSE}
icu_adm <- adm %>% 
  left_join(icu, by = c("SUBJECT_ID", "HADM_ID"))

str(icu_adm)
```

Note: in the same way each subject/patient could have multiple `HADM_ID` from different hospital admissions during the EHR course of the MIMIC database, each `HADM_ID` can have multiple `ICUSTAY_ID`.

# Data transformation

## Exercise

Aim: To transform the presentation of data values in some ways so that the new format is more suitable for the subsequent statistical analysis. The main processes involved are normalization, aggregation and generalization.

1. Base data extractions:

This extraction relies on a (very complicated) view that was provided with the original course material on the github site for the course.  As such, it uses a lower level database routine for extraction.

The view uses data from the `DIAGNOSES_ICD`, `DRGCODES` and `ADMISSIONS` tables to implement a version of the Elixhauser Comorbidity Index.  The Elixhauser Comorbidity Index is a method of categorizing comorbidities of patients based on the International Classification of Diseases (ICD) diagnosis codes.

```{r message=FALSE, warning=FALSE}
Elixhauser <- db_select_data(mimic3, "SELECT * FROM ELIXHAUSER_AHRQ")

str(Elixhauser)
```

Note the total number of rows (obs) and columns (variables) in `Elixhauser` tibble results.

2. R code: Demonstrating data transformation

### Aggregation and Normalization steps

Here we `mutate` the `Elixhauser` tibble to add an `OVERALL_SCORE` column which is the sum of all of the co-morbidity values, and a normalized value - `OVERALL_NML` - of each observation's `OVERALL_SCORE` divided by the maximum `OVERALL_SCORE` for the sample.

(Note: in this updated version, the aggregation and normalization are done in a single `mutate` rather than a series of base R steps.)

```{r message=FALSE, warning=FALSE}
Elixhauser <- Elixhauser %>% 
  mutate(
    OVERALL_SCORE = rowSums(select(., CONGESTIVE_HEART_FAILURE:DEPRESSION)),
    OVERALL_NML = OVERALL_SCORE/max(OVERALL_SCORE)
  )

str(Elixhauser)
```

### Generalization Step

Aim: Consider only the group of patients sicker than the average Elixhauser score.  Here, we will create a new tibble `Elixhauser_sicker_sample` of those subjects from the whole sample who have an `OVERALL_NML` value >= 0.5 - the sickest half of the population based on number of morbidity indications.  For this tibble, we will keep the `SUBJECT_ID`, `HADM_ID`, and `OVERAL_NML` values only.  We will save that to the CSV file:  `sicker_sample.csv`

```{r message=FALSE, warning=FALSE}
Elixhauser_sicker_sample <- Elixhauser %>% 
  filter(OVERALL_NML >= 0.5) %>% 
  select(SUBJECT_ID, HADM_ID, OVERALL_NML)

str(Elixhauser_sicker_sample)

write.csv(Elixhauser_sicker_sample,
          fs::path(base_dir, "exercises/data_preprocessing/Elixhauser_sicker_sample.csv"), row.names = FALSE)
```

# Data reduction

## Exercise

Aim: To reduce or reshape the input data by means of a more effective representation of the dataset without compromising the integrity of the original data. One element of data reduction is eliminating redundant records while preserving needed data, which we will demonstrate in Part 1. The other element involves reshaping the dataset into a "tidy" format, which we will demonstrate in Part 2.

### Part 1: Eliminating Redundant Records

To demonstrate this with an example, we will look at multiple records of glucose laboratory values for each patient.  This query selects all the non-null measurements of glucose values for all the patients in the MIMIC database.

(Note:  I was not sure if - in the original course example - they used the demo database or the full database for this analyses, so I went with the full database.  That will be my default from now on unless it is otherwise specified in the older Rmarkdown code.)

1. Base data extractions:

```{r message=FALSE, warning=FALSE}
where <- "WHERE (itemid = 50931 OR itemid = 50809)  
          AND   valuenum IS NOT null
          AND   hadm_id IS NOT null"
all_glucose <- db_get_labevents(mimic3, where = where)

str(all_glucose)
```

2. R code: Demonstrating data reduction

There are a variety of methods that can be chosen to aggregate records. In this case we will look at averaging multiple glucose records into a single average glucose for each patient. Other options which may be chosen include using the first recorded value, a minimum or maximum value, etc. For a basic example, the following code demonstrates data reduction by averaging all of the multiple records of glucose into a single record per patient hospital admission. The code uses the `tidyverse` package functions `group_by` and `aggregate` to calculate average glucose values for each distinct `HADM_ID`:

```{r message=FALSE, warning=FALSE}
avg_glucose <- all_glucose %>% 
    arrange(HADM_ID, SUBJECT_ID) %>%
    group_by(HADM_ID, SUBJECT_ID) %>%
    summarize(
      VALUENUM = mean(VALUENUM, na.rm = TRUE)
    )

avg_glucose
```

### Part 2: Reshaping Dataset

Ideally, we want a "tidy" dataset reorganized in such a way so it follows these 3 rules:

* 1. Each variable forms a column
* 2. Each observation forms a row
* 3. Each value has its own cell

Datasets exported from MIMIC usually are fairly "tidy" already. Therefore, we will construct our own data frame here for ease of demonstration for rule 3. We will also demonstrate how to use some common data tidying packages.

R code: To mirror our own MIMIC dataframe, we construct a dataset with a column of `subject_id` and a column with a list of `diagnoses` for the admission.

(Note:  this versions of the code is from the original with only slight modifications.)

```{r message=FALSE, warning=FALSE}
diag <- data.frame(subject_id = 1:6, diagnosis = c("PNA, CHF", "DKA", "DKA, UTI", "AF, CHF", "AF", "CHF"))

diag
```

Note that the dataset above is not "tidy". There are multiple categorical variables in column "diagnosis" - breaks "tidy" data rule 1. There are multiple values in column "diagnosis" - breaks "tidy" data rule 3. There are many ways to "tidy" and reshape this dataset. We will show one way to do this by making use of R packages "splitstackshape" and "tidyr" to make reshaping the dataset easier.

#### R package example 1 - `splitstackshape` package functions:

The function, `cSplit` from the `splitstackshape` package, can split the multiple categorical values in each cell of column `diagnosis` into different columns, `diagnosis_1` and `diagnosis_2`. If the argument, direction, for `cSplit` is not specified, then the function splits the original dataset "wide".

```{r message=FALSE, warning=FALSE}
diag2 <- cSplit(diag, "diagnosis", ",")

diag2
```

One could possibly keep it as this if one is interested in primary and secondary diagnoses (though it is not strictly "tidy" yet). Alternatively, if the direction argument is specified as "long", then `cSplit` splits the function "long" like so:

```{r message=FALSE, warning=FALSE}
diag3 <- cSplit(diag, "diagnosis", ",", direction = "long")

diag3
```

Note diag3 is still not "tidy" as there are still multiple categorical variables under
column diagnosis-but we no longer have multiple values per cell. 

#### R package example 2 - `tidyr` package functions:

To further "tidy" the dataset, package `tidyr` is pretty useful.

The aim is to split each categorical variable under column `diagnosis` into their own columns with 1 = having the diagnosis and 0 = not having the diagnosis. To do this we first construct a third column, `yes`, that hold all the 1 values initially (because the function we are going to use requires a value column that corresponds to the multiple categories column we want to 'spread' out).

```{r message=FALSE, warning=FALSE}
diag3$yes <- rep(1, nrow(diag3))

diag3
```

Then we can use the `spread` function to split each categorical variables into their own columns. The argument, fill = 0, replaces the missing values.

```{r message=FALSE, warning=FALSE}
diag4 <- spread(diag3, diagnosis, yes, fill = 0)

diag4
```

One can see that this dataset is now "tidy", as it follows all three "tidy" data rules.

```{r finish, include=FALSE}
dbDisconnect(mimic3)
```
